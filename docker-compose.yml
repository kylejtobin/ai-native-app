# =============================================================================
# AI-Native App Architecture - Docker Compose
# =============================================================================
# This file defines a complete polyglot persistence stack.
#
# Architecture Philosophy:
#   - Use the right database for each job (not one-size-fits-all)
#   - Services start in dependency order (healthchecks + depends_on)
#   - Setup scripts run once via condition: service_completed_successfully
#   - All secrets come from .env (never hardcoded)
#
# Service Categories:
#   1. Core Data: PostgreSQL, Redis
#   2. Specialized: Neo4j (graph), Qdrant (vector), MinIO (object storage)
#   3. LLM: Ollama (optional local inference)
#   4. Application: FastAPI (your Python app)
#
# Volumes:
#   - All data persists across restarts (unless you `make clean`)
#   - Named volumes (not bind mounts) for better performance

name: an-app

services:
  # ===========================================================================
  # PostgreSQL - Relational Database (ACID Transactions)
  # ===========================================================================
  # Use for: User data, orders, structured business data
  # Why: ACID guarantees, complex queries, foreign keys, transactions
  # Extensions: uuid-ossp (UUIDs), pg_trgm (fuzzy search), unaccent (text search)
  postgres:
    image: postgres:17-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: appdb
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}  # Generated by infra/generate-config.sh
    volumes:
      - postgres_data:/var/lib/postgresql/data  # Persistent data storage
      - ./infra/init-db.sql:/docker-entrypoint-initdb.d/init.sql  # Runs on first start
    ports:
      - "5432:5432"  # Exposed for local development (psql, DBeaver, etc.)
    healthcheck:
      test: pg_isready -U appuser -d appdb  # Simple readiness check
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================================================
  # Redis - In-Memory Cache & Message Broker
  # ===========================================================================
  # Use for: Session storage, caching, pub/sub, queues, conversation history
  # Why: Microsecond latency, atomic operations, TTL support, pub/sub primitives
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD}  # Require auth for security
    volumes:
      - redis_data:/data  # AOF/RDB persistence (survives restarts)
    ports:
      - "6379:6379"  # Exposed for redis-cli, GUI clients
    healthcheck:
      test: redis-cli -a ${REDIS_PASSWORD} ping  # Auth-aware healthcheck
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================================================
  # Neo4j - Graph Database
  # ===========================================================================
  # Use for: Relationships, social networks, knowledge graphs, recommendation engines
  # Why: Traversals are O(1), pattern matching with Cypher, relationship-first thinking
  # Plugins: APOC (graph algorithms, procedures)
  neo4j:
    image: neo4j:5-community
    restart: unless-stopped
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD}  # Format: username/password
      NEO4J_PLUGINS: '["apoc"]'  # APOC: Awesome Procedures on Cypher
    volumes:
      - neo4j_data:/data  # Graph storage
      - neo4j_logs:/logs  # Query logs, debug logs
    ports:
      - "7474:7474"  # Browser UI (http://localhost:7474)
      - "7687:7687"  # Bolt protocol (driver connections)
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  # Neo4j Initialization - Runs Cypher Scripts Once
  # Pattern: One-time setup container that exits after running init scripts
  neo4j_setup:
    image: neo4j:5-community
    depends_on:
      neo4j:
        condition: service_healthy  # Waits for Neo4j to be ready
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD}
      NEO4J_URI: bolt://neo4j:7687
    volumes:
      - ./infra/setup-neo4j.sh:/setup-neo4j.sh  # Setup script
      - ./infra/init.cypher:/infra/init.cypher  # Cypher initialization queries
    entrypoint: ["/bin/bash", "/setup-neo4j.sh"]  # Override to run our script
    restart: "no"  # Exits after running (condition: service_completed_successfully)

  # ===========================================================================
  # Qdrant - Vector Database
  # ===========================================================================
  # Use for: Semantic search, RAG, similarity matching, embeddings storage
  # Why: Optimized for vector operations, HNSW indexing, metadata filtering
  qdrant:
    image: qdrant/qdrant:latest
    restart: unless-stopped
    volumes:
      - qdrant_storage:/qdrant/storage  # Vector index and metadata storage
    ports:
      - "6333:6333"  # REST API (main interface)
      - "6334:6334"  # gRPC API (higher performance)

  # ===========================================================================
  # Ollama - Local LLM Inference (Optional)
  # ===========================================================================
  # Use for: Private LLM inference, no API costs, offline development
  # Why: Run models like Llama 3.2, Mistral, CodeLlama locally
  # Note: Optional - requires GPU for good performance, CPU inference is slow
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    environment:
      OLLAMA_HOST: 0.0.0.0  # Listen on all interfaces (Docker network)
    volumes:
      - ollama_models:/root/.ollama  # Model weights storage (can be large!)
    healthcheck:
      test: curl -f http://localhost:11434/api/version || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "11434:11434"  # OpenAI-compatible API


  # ===========================================================================
  # MinIO - S3-Compatible Object Storage
  # ===========================================================================
  # Use for: File uploads, documents, images, LLM artifacts, backups
  # Why: S3-compatible API, organized buckets, versioning, policies
  minio:
    image: minio/minio:latest
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}  # Admin access key
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}  # Admin secret key
    volumes:
      - minio_data:/data  # Object storage data
    command: server /data --console-address ":9001"  # Start server + web UI
    healthcheck:
      test: curl -f http://localhost:9000/minio/health/live || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "9000:9000"  # S3 API (boto3, aws-cli compatible)
      - "9001:9001"  # Web Console (http://localhost:9001)

  # MinIO Initialization - Create Buckets Once
  # Pattern: Uses mc (MinIO Client) to configure buckets and policies
  minio_setup:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy  # Waits for MinIO to be ready
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    volumes:
      - ./infra/setup-minio.sh:/setup-minio.sh  # Bucket creation script
    entrypoint: ["/bin/bash", "/setup-minio.sh"]  # Run our setup script
    restart: "no"  # Exits after running

  # ===========================================================================
  # FastAPI Application - Your Python API
  # ===========================================================================
  # This is your API service - where the magic happens
  # Architecture: Clean separation of API, Service, Domain layers
  # Hot reload: src/ is mounted as volume for live code updates
  api:
    build: .  # Uses Dockerfile in repo root
    restart: unless-stopped
    ports:
      - "8000:8000"  # HTTP API
    env_file:
      - .env  # Load all environment variables from generated .env
    environment:
      # Explicit environment variables for IDE visibility and debugging
      # (Docker Compose will use values from .env file)
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      QDRANT_URL: ${QDRANT_URL}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
      MINIO_ENDPOINT: ${MINIO_ENDPOINT}
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      MINIO_SECURE: ${MINIO_SECURE}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      API_HOST: ${API_HOST}
      API_PORT: ${API_PORT}
      ENVIRONMENT: ${ENVIRONMENT}
      LOG_LEVEL: ${LOG_LEVEL}
    volumes:
      - ./src:/app/src  # Hot reload: edits reflect immediately (no restart needed)
    depends_on:
      # Dependency graph: app starts only after all infrastructure is ready
      postgres:
        condition: service_healthy  # Database must be accepting connections
      redis:
        condition: service_healthy  # Cache must be ready
      neo4j_setup:
        condition: service_completed_successfully  # Graph must be initialized
      qdrant:
        condition: service_started  # Vector DB ready (no healthcheck needed)
      minio_setup:
        condition: service_completed_successfully  # Buckets must exist
      ollama:
        condition: service_started  # LLM inference available (optional)

# =============================================================================
# Named Volumes - Data Persistence
# =============================================================================
# These volumes survive container restarts and rebuilds (unless you `make clean`)
# Data lives here, not in containers (containers are ephemeral)
volumes:
  postgres_data:    # Relational data, tables, indexes
  redis_data:       # Cache, queues, conversation history
  neo4j_data:       # Graph nodes, relationships
  neo4j_logs:       # Query logs, slow query analysis
  qdrant_storage:   # Vector embeddings, HNSW indexes
  ollama_models:    # LLM model weights (large!)
  minio_data:       # Object storage buckets